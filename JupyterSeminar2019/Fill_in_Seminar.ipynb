{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "# Jupyter Mini-Crash Course: Biowulf, R vs. Python, and Swarms\n",
    "- **Written By:** Mary B. Makarious and Hirotaka Iwaki \n",
    "- **Last Updated:** 01.08.2019\n",
    "- **Written In:** Python 3.7 (Check to see the kernel on the top right!)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "**Reproducibility** is the key to robust science. Keeping your code in a way that anybody can trace what you have done is important. \n",
    "\n",
    "**Jupyter Notebook** is an efficient tool for sharing your analysis in a reproducible form. Another advantage of using jupyter notebook is that you can utilize the power of Biowulf so that you can adapt many techniques to **accerelate your analyses**.\n",
    "As trial-and-error is necessary for scripting, spinning this cycle as fast as possible is critical. \n",
    "\n",
    "**What is Jupyter?** The name Jupyter is an indirect acronym of the three core languages it was designed for: **JU**lia, **PYT**hon, and **R** and is inspired by the planet Jupiter.\n",
    "\n",
    "A previous summer student created a neat mini-intro to Jupyter as a whole that you can find [here](https://github.com/neurogenetics/seminar/blob/master/Examples%20and%20Tutorials/NotebooksTutorial.ipynb)\n",
    "\n",
    "## What We Will Cover Today\n",
    "#### [0. Files and Logistics](#Files)\n",
    "#### [1. Benefits to Using Jupyter Notebooks/Lab](#Getting-Started)\n",
    "#### [2. Setting Up *expect* Scripts](#Setting-Up)\n",
    " - 2.1) Running Scripts and Setting Up Interactive Nodes\n",
    "\n",
    "#### [3. Incorporating R, bash, and Other Languages](#Dif-Lang)\n",
    " - 3.1) Running bash and a bash loop\n",
    " - 3.2) Running R \n",
    " \n",
    "#### [4. Common R Functions in Python](#R-Python)\n",
    "\n",
    "#### [5. How to plot in R with ggplot within the Lab/Notebook](#R-Plot)\n",
    "#### [6. How to plot in Python with seaborn within the Lab/Notebook](#Py-Plot)\n",
    "#### [7. How to Submit Swarm Files to Biowulf from within the Lab/Notebook](#Swarms)\n",
    "#### [8. Take-away Messages](#Bye)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Files\"></a>\n",
    "# 0. Files and Logistics\n",
    "\n",
    "**GitHub Repository:** https://github.com/neurogenetics/talks/tree/master/JupyterSeminar2019\n",
    "\n",
    "Throughout this seminar, we will be using dummy data for demonstration.\n",
    "\n",
    "## If you plan on using your own Biowulf account...\n",
    "1. Follow the link on the screen\n",
    "2. Download the .zip file \n",
    "3. Copy over the data to your desired directory on Biowulf (locally)\n",
    " - `scp -r /downloaded/file/file.zip yourBiowulfusername@biowulf.nih.gov:/desired/directory/here` \n",
    "4. `gunzip` the file \n",
    "\n",
    "## If you plan on using one of the student accounts...\n",
    "1. Password: On handout\n",
    "2. I have already made a directory called `JupyterSeminar2019` with all the materials needed\n",
    "3. When the time comes, you will `cd` into that directory. \n",
    "\n",
    "These zip files contain only the **data** we will be using. \n",
    "In Module 2, we will be generating our own scripts, not included in the zip file/directory already\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Getting-Started\"></a>\n",
    "# 1. Benefits to Using Jupyter Notebooks/Lab\n",
    "\n",
    "- Saves all the output within the notebook! \n",
    "    - This includes plots, outcomes of shell scripts, etc.\n",
    "- Run in chunks -- which is good for troubleshooting \n",
    "- Can include Markdown chunks\n",
    "    - This is a markdown chunk!\n",
    "    - These are great for explaining what's going on, giving a structure to documentation, and replication later\n",
    "- Can run chunks of different languages \n",
    " - R, bash, Julia, Python, and many more outlined [here](https://github.com/jupyter/jupyter/wiki/Jupyter-kernels)!\n",
    "- Can generate presentation slides directly from the notebook \n",
    "- Can generate an HTML or PDF that is shareable \n",
    "    - These include all the outputs that you see as well, beneficial for replication \n",
    "- In JupyterLab: Can have a Terminal window open as well in the same environment \n",
    "\n",
    "## Limitations:\n",
    "- When running Jupyter on Biowulf, it is like running anything else. You are limited to the packages that are preinstalled in the kernel.\n",
    "- Should you need additional packages, `!pip install` and `conda install` are not available (and would need to look into making your own environment to do so) \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Setting-Up\"></a>\n",
    "# 2. Setting Up *expect* Scripts\n",
    "\n",
    "2 scripts are necessary to start a Jupyter notebook in Biowulf, which will be saved as `first.txt` and `second.txt`.\n",
    "\n",
    "These 2 files will be saved somewhere on your Desktop and will be accessed via the terminal.\n",
    "\n",
    "For both of these scripts, you will **need to change** the username to be your own username when you make them.\n",
    "\n",
    "Paste the following chunk into a text file that you will name `first.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash \n",
    "# Set user name\n",
    "set USER yourBiowulfusernamehere\n",
    "\n",
    "# grab the password \n",
    "stty -echo\n",
    "send_user -- \"Password for ${USER}@biowulf.nih.gov: \"\n",
    "expect_user -re \"(.*)\\n\"\n",
    "send_user \"\\n\"\n",
    "stty echo\n",
    "set PASS $expect_out(1,string)\n",
    "\n",
    "# Login and set up interactive node\n",
    "set timeout -1\n",
    "spawn env LANG=C /usr/bin/ssh ${USER}@biowulf.nih.gov\n",
    "expect {\n",
    "    \"${USER}@biowulf.nih.gov's password: \" {\n",
    "        send \"${PASS}\\n\"\n",
    "    }\n",
    "}\n",
    "expect {\n",
    "    \"\\\\\\$\" {\n",
    "        send \"module load tmux;tmux\\n\"\n",
    "    }\n",
    "}\n",
    "expect {\n",
    "    \"\\\\\\$\" {\n",
    "        send \"sinteractive --tunnel --cpus-per-task=2 --mem=200g --gres=lscratch:200 --time=13:00:00\\n\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Write out the allocated port, install modules frequently used, and set up jupyterLab\n",
    "## you may like to go to a different directory before setting up the jupyter lab\n",
    "expect {\n",
    "    \"\\\\\\$\" {\n",
    "        send \"echo \\${PORT1} > sinteractive_port.txt; \\\n",
    "        module load R; \\\n",
    "        cd /data/${USER}; \\\n",
    "        module load annovar; \\\n",
    "        module load plink; \\\n",
    "        module load flashpca; \\\n",
    "        module load jupyter;jupyter lab --ip localhost --port \\${PORT1} --no-browser\\n\"\n",
    "    }\n",
    "}\n",
    "interact\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, paste the next chunk as `second.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "# User name \n",
    "set USER yourBiowulfusernamehere\n",
    "\n",
    "# grab the password \n",
    "stty -echo\n",
    "send_user -- \"Password for ${USER}@biowulf.nih.gov: \"\n",
    "expect_user -re \"(.*)\\n\"\n",
    "send_user \"\\n\"\n",
    "stty echo\n",
    "set PASS $expect_out(1,string)\n",
    "\n",
    "# Download port information for sinteractive node\n",
    "spawn scp ${USER}@biowulf.nih.gov:/home/${USER}/sinteractive_port.txt .\n",
    "expect {\n",
    "    \"${USER}@biowulf.nih.gov's password: \" {\n",
    "        send \"${PASS}\\n\"\n",
    "    }\n",
    "}\n",
    "expect {\"\\\\\\$\"} # Wait until the download finishes\n",
    "\n",
    "# Tunnel to the sinteractive node\n",
    "set NODE [exec cat sinteractive_port.txt]\n",
    "spawn /usr/bin/ssh -L ${NODE}:localhost:${NODE} biowulf.nih.gov\n",
    "expect {\n",
    "    \"${USER}@biowulf.nih.gov's password: \" {\n",
    "        send \"${PASS}\\n\"\n",
    "    }\n",
    "}\n",
    "interact\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    ".\n",
    "## 2.1 Running *expect* Scripts to Login and Tunnel to the `sinteractive` node\n",
    "\n",
    "After creating the above `.txt` files, run the first command (that is saved somewhere on your local computer) and wait until sinteractive node is set up\n",
    "\n",
    "`expect first.txt`\n",
    "\n",
    "Open a new Terminal window, and run the second command\n",
    "\n",
    "`expect second.txt`\n",
    "    \n",
    "Great! Now we can connect to Jupyter!\n",
    "If you go back to the Terminal with the interactive node, there should be a path that looks like the following \n",
    "\n",
    "`http://localhost:37674/?token=123456789123456789`\n",
    "\n",
    "Go ahead highlight this, right click, and open URL. This should open in your default web browser\n",
    "\n",
    "### Notes: \n",
    "1. You need to customize your `first.txt` as needed for modules you want to include or home directory you want to start in\n",
    " - (For example, I assume that the list of software you frequently use is different from mine.)\n",
    "2. In the `first.txt` script, we use tmux\n",
    " - Because with tmux, we donâ€™t need to set up sinteractive node after every incidental disconnection\n",
    " - We just run the `second.txt` and resume our analysis. It saves a lot of time when we are working wirelessly or remotely\n",
    " \n",
    " # Let's Try This Out!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"Dif-Lang\"></a>\n",
    "# 3. Incorporating R, bash, and Other Languages "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "### 3.1 Bash\n",
    "\n",
    "### Things to Keep in Mind:\n",
    "- The beginning of the chunk needs to start with `%%bash`\n",
    "- You can make variables and arrays like you normally would, but everything is contained in the chunk and will not transfer over\n",
    "- You can save output from a bash script to use in a Python chunk later using (!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# You can assign variables\n",
    "#YOUR CODE HERE\n",
    "\n",
    "# You can also perform loops \n",
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can mix and match Python and bash\n",
    "#YOUR CODE HERE\n",
    "\n",
    "# You can read in input from the terminal to use in Python\n",
    "# Using !, you can incorporate the results from Terminal into your Python scripts\n",
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "### 3.2 R\n",
    "\n",
    "### Things to Keep in Mind:\n",
    "- The beginning of the chunk needs to start with `%%bash`, same as before. But will also have the following line: `R --slave --vanilla`\n",
    "- Everything contained in the chunk will not be transferred over, same as before \n",
    " - Though, you can look into the `%%Rpush` and `%%Rpull` documentation if you are interested in transferring things between Python and R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Managing data in R with tidyverse and data.table\n",
    "R --slave --vanilla # options for running R\n",
    "\n",
    "# Load the necessary packages \n",
    "suppressMessages(library('tidyverse'))\n",
    "suppressMessages(library('data.table'))\n",
    "\n",
    "# Read in the .fam file (from example PLINK data)\n",
    "fam <- fread(\"hapmap1.fam\", header = FALSE)\n",
    "\n",
    "# See the first few lines \n",
    "head(fam)\n",
    "\n",
    "# Get the dimensions of the dataset\n",
    "dim(fam)\n",
    "\n",
    "# Add column names to the dataset\n",
    "colnames(fam)<- c(\"FID\", \"IID\", \"PAT\", \"MAT\", \"SEX\", \"PHENO\")\n",
    "\n",
    "# Change a column name \n",
    "fam_rename <- fam %>% rename(\"PHENOTYPE\" = \"PHENO\") # Can be done in place\n",
    "head(fam_rename)\n",
    "\n",
    "# Make a new column (print out if case or control)\n",
    "fam_rename$CASE_OR_CONTROL <- ifelse(fam_rename$PHENOTYPE == 1, \"CONTROL\", \"CASE\")\n",
    "head(fam_rename)\n",
    "\n",
    "# Subset the data\n",
    "fam_cases = fam_rename %>% filter(CASE_OR_CONTROL == \"CASE\")\n",
    "head(fam_cases)\n",
    "dim(fam_cases)\n",
    "\n",
    "# Write out the file \n",
    "write.table(fam_cases, file = \"updated_fam_file_R.csv\", col.names=FALSE, row.names=FALSE, na=\"\", quote=FALSE, sep=\"\\t\")\n",
    "\n",
    "# Loop\n",
    "x <- c(2,5,3,9,8,11,6)\n",
    "\n",
    "# For loop\n",
    "count <- 0\n",
    "for (value in x) {\n",
    "    if(value %% 2 == 0)\n",
    "    count = count+1\n",
    "}\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"R-Python\"></a>\n",
    "# 4. Common R Functions in Python\n",
    "\n",
    "Scientists and statisticians prefer to use R.\n",
    "\n",
    "However, a lot of the common file manipulating is similar.\n",
    "\n",
    "\n",
    "Below is a demonstration of what we did above in R, but in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Managing data in Python with pandas \n",
    "\n",
    "# Load the necessary packages \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "# Read in the .fam file (from example PLINK data)\n",
    "#YOUR CODE HERE\n",
    "\n",
    "# See the first few lines \n",
    "#YOUR CODE HERE\n",
    "\n",
    "# Get the dimensions of the dataset\n",
    "#YOUR CODE HERE\n",
    "\n",
    "# Add column names to the dataset\n",
    "#YOUR CODE HERE\n",
    "\n",
    "# Change a column name \n",
    "#YOUR CODE HERE\n",
    "\n",
    "# Make a new column (print out if case or control)\n",
    "#YOUR CODE HERE\n",
    "\n",
    "# Subset the data \n",
    "#YOUR CODE HERE\n",
    "\n",
    "# Write out the file \n",
    "fam_cases.to_csv (\"updated_fam_file_Python.csv\", index=None, header=None)\n",
    "\n",
    "# Creating loops in Python \n",
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"R-Plot\"></a>\n",
    "# 5. How to plot in R with ggplot within the Lab/Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# This script is how to generate a Scree plot using the ggplot package in R \n",
    "R --slave --vanilla # options for running R\n",
    "\n",
    "# Load the necessary packages \n",
    "suppressMessages(library('tidyverse'))\n",
    "suppressMessages(library('ggplot2'))\n",
    "suppressMessages(library('data.table'))\n",
    "\n",
    "# Read in the PCA Eigenvalues and Eigenvectors \n",
    "print(\"Read in pca.eigenval file from PLINK\")\n",
    "eigenval <- fread(\"pcaCovs_LBD.eigenval\", header = FALSE)\n",
    "\n",
    "# Update column names\n",
    "print(\"Update the column names\")\n",
    "colnames(eigenval)[1] <- \"Eigenvalues\"\n",
    "eigenval$PC <- as.numeric(rownames(eigenval))\n",
    "eigenval$VarianceExplained <- eigenval$Eigenvalues/sum(eigenval$Eigenvalues)*100\n",
    "eigenval2 <- head(eigenval,10)\n",
    "\n",
    "print(\"Generate the Scree plot\")\n",
    "scree <- ggplot(data = eigenval2, aes(x = PC, y = VarianceExplained)) +\n",
    "  geom_line() + \n",
    "  geom_point() +\n",
    "  theme_bw() +\n",
    "  theme(panel.grid.minor = element_blank()) + \n",
    "  scale_x_continuous(name = \"Principal Components\", breaks = seq(0,10,1), limits = c(NA,10)) +\n",
    "  scale_y_continuous(name = \"Percent (%) Variance Explained\", breaks = seq(0,50,5), limits = c(0,50)) +\n",
    "  ggtitle(\"Scree Plot: \\n LBD GWAS \\n (1,046 Cases; 34,571 Controls)\") +\n",
    "  theme(plot.title = element_text(hjust = 0.5, face = \"bold\"))\n",
    "\n",
    "print(\"Save out the plot\")\n",
    "ggsave(\"ScreePlot_LBD_GWAS_R.jpg\", scree, width = 5, height = 3.5, units = \"in\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To display the image made in the R script above\n",
    "from IPython.display import Image\n",
    "Image(filename=\"ScreePlot_LBD_GWAS_R.jpg\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"Py-Plot\"></a>\n",
    "# 6. How to plot in Python with seaborn within the Lab/Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script is how to generate the same Scree plot using the seaborn package in Python\n",
    "\n",
    "# Load the necessary packages \n",
    "import seaborn as sns\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Read in the PCA Eigenvalues and Eigenvectors \n",
    "print(\"Read in pca.eigenval file from PLINK\")\n",
    "#YOUR CODE HERE\n",
    "\n",
    "# Update column names\n",
    "print(\"Update the column names\")\n",
    "#YOUR CODE HERE\n",
    "\n",
    "print(\"Generate the Scree plot\")\n",
    "\n",
    "# Stylistic Plot Requirements  \n",
    "sns.set_context(\"poster\") # Many other options, this works well within Jupyter\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)}, font_scale=3)\n",
    "\n",
    "# Plotting the plot\n",
    "#YOUR CODE HERE\n",
    "\n",
    "# Save out the figure\n",
    "scree.figure.savefig(\"ScreePlot_LBD_GWAS_Python.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"Swarms\"></a>\n",
    "# 7. How to Submit Swarm Files to Biowulf from within the Lab/Notebook\n",
    "\n",
    "## Biowulf Modules and Swarm Submissions\n",
    "\n",
    "- User Dashboard: [LINK](https://auth.nih.gov/CertAuthV2/forms/NIHPivOrFormLogin.aspx?TYPE=33554433&REALMOID=06-effe824d-683e-408e-962c-86fed36d3317&GUID=&SMAUTHREASON=0&METHOD=GET&SMAGENTNAME=-SM-aKmoe5cvpd5WMc7bZS8DqazGggT0l50j5WjH2pgUXDKXvzHEQOnbTYJNejNHZ%2bzw&TARGET=-SM-https%3a%2f%2fhpc%2enih%2egov%2fdashboard%2f#)\n",
    "\n",
    "### Things to Keep in Mind:\n",
    "- You can load modules like you would in Biowulf, but they are limited to the chunk you are using unless they were specified in your `first.txt` script (output is saved in Notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Load the necessary modules \n",
    "module load plink\n",
    "\n",
    "# For example, you can run basic QC within Jupyter\n",
    "# For example, call rate \n",
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say for example you want to extract each chromosome out to binary files to use later \n",
    "\n",
    "You can do this by\n",
    "- One by one\n",
    "- In a loop \n",
    "- Running an external script\n",
    "- In a swarm \n",
    "\n",
    "Since we have already discussed loops, I will now discuss running an external script\n",
    "\n",
    "Say that the external script `subset_by_chr.sh` looks like this...\n",
    "\n",
    "```bash\n",
    "#!/bin/env bash\n",
    "\n",
    "mkdir PLINK_SUBSET\n",
    "\n",
    "module load plink \n",
    "\n",
    "for chromosome in {1..22};\n",
    "do\n",
    "    plink --bfile hapmap1_CR --chr ${chromosome} --make-bed --out ./PLINK_SUBSET/CHR${chromosome}_hapmap1_CR \n",
    "done\n",
    "```\n",
    "\n",
    "You can run it using the following..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "%%bash \n",
    "\n",
    "# %%capture at the top is to hide output of the cell in case it is really long\n",
    "\n",
    "# Run the script\n",
    "#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also prepare to submit a swarm within Jupyter like the following...\n",
    "\n",
    "One way is to write a bash script for-looping each chromosome and submit them with sbatch. \n",
    "However, using swarm is better because it is more efficient, tracable and controllable. \n",
    "\n",
    "I especially like that with swarm, you can explicitly use two cpus on one core, which is twice more efficient! Let's create a swarm file for generating chr1-22."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary = 'hapmap1_CR'\n",
    "script = \"\"\"\n",
    "    plink --bfile {binary} --chr {chromosome} --make-bed --out ./PLINK_SUBSET/CHR{chromosome}_{binary}\"\"\"\n",
    "\n",
    "with open ('subset_by_chr.swarm', 'w') as f:\n",
    "    for chromosome in range(1,23):\n",
    "        f_out = 'chromosome '+str(chromosome)\n",
    "        f.write(script.format(binary = binary, chromosome = chromosome, \n",
    "                              f_out = f_out))\n",
    "        print(f_out, 'done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "## Submitting a Swarm\n",
    "Before actually submitting a swarm job, it is always good to check how it would go with *--devel* option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!swarm -f subset_by_chr.swarm --module plink --devel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "### +++**IMPORTANT**+++\n",
    "\n",
    "To decide parameters, please go to [User Dashboard](https://hpc.nih.gov/dashboard/). \n",
    "\n",
    "It seems that the above command only takes <100M memory, 1 cpu, and 2 min with the current parameters (which there are none)\n",
    "\n",
    "The job scheduling priority is determined by your past CPU usage (**sum of CPUxTIME**) with a half life of 2 weeks. \n",
    "\n",
    "Setting parsimoneous parameters is important to get the job done!\n",
    "\n",
    "\n",
    "So I set the parameters as, \n",
    "\n",
    "1. 2G memory will be more than enough: -g 2\n",
    "2. Use both cpus for a core : -p 2\n",
    "3. Give 1 min per job: --time '00:01:00'\n",
    "4. Bundle 2 subjobs so that each subjob works more than 5 min (for scheduling efficiency): -b 6\n",
    "5. Designate the output folder \"PLINK_SUBSET\"\n",
    "6. Submit job to \"quick\" node since the running time for the job won't exceed 4 hours\n",
    "\n",
    "**Looks Good?**\n",
    "\n",
    "Now submit the job by taking away *--devel*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!swarm -f subset_by_chr.swarm -g 2 -p 2 --time '0:01:00' -b 6 --logdir='PLINK_SUBSET' --partition='quick' --module plink --devel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!swarm -f subset_by_chr.swarm -g 2 -p 2 --time '0:01:00' -b 6 --logdir='PLINK_SUBSET' --partition='quick' --module plink "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jobload -j 32793996"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"Bye\"></a>\n",
    "# 8. Take-away Messages\n",
    "\n",
    "Hopefully, at the conclusion of this seminar you know: \n",
    "1. How to use the expect scripts to set up Jupyter within Biowulf\n",
    "2. You know how to manipulate the expect scripts to open in the preferred directory with the loaded modules \n",
    "3. You are aware of some of the other languages you can use within Jupyter and their limitations\n",
    "4. You can see how to run scientists and statistician's favorite language: R\n",
    "5. You can also see how some of the more common things done in R look like in Python\n",
    "6. What ggplot looks like within Jupyter\n",
    "7. How to create similar plots in Python\n",
    "8. How to submit swarm file \n",
    "\n",
    "Any questions/comments? Please email me at mary.makarious@nih.gov\n",
    "\n",
    "**Please remember to fill out the survey! :)** \n",
    "\n",
    "#### Future Talks: \n",
    "- **09/19:** Tracing Tools for Neuronal Circuit Mapping\n",
    "- **10/11:** Neurodegenerative Diseases (Clinic, Pathology, Genetics) \n",
    "- **10/25:** ImageJ - Organelle Dynamics and Cell Morphology Analysis \n",
    "\n",
    "**Would you like to see other talks?** (ex. GitHub introduction, How to Run a GWAS, etc.) please email chiarp@nih.gov with suggestions of what you would like to see or present!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python/3.7",
   "language": "python",
   "name": "py3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
